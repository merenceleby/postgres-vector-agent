# ğŸ¤– Auto-Tuning PostgreSQL Vector Store Agent

An autonomous AI agent that monitors, analyzes, and optimizes PostgreSQL vector similarity search performance using LLM-powered decision making for production RAG workloads.

[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue)](https://www.postgresql.org/)
[![Python](https://img.shields.io/badge/Python-3.10+-green)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

---

## ğŸ¯ Project Overview

This project demonstrates an **agentic coding** approach to database optimization for AI workloads. The agent autonomously:

1. **ğŸ‘ï¸ Observes** query performance using PostgreSQL `EXPLAIN ANALYZE`
2. **ğŸ§  Reasons** about optimization strategies using local LLM (Ollama/Phi-3)
3. **âš¡ Acts** by creating vector indexes (HNSW/IVFFlat) without human intervention
4. **âœ… Verifies** improvements through continuous performance monitoring

Built to demonstrate expertise in **PostgreSQL internals**, **distributed systems**, and **agentic AI** for Azure Database services roles.

---

## ğŸ“Š Performance Results

**Benchmark on 995 Wikipedia articles:**

| Query | Before | After | Improvement |
|-------|--------|-------|-------------|
| AI & ML | 10.99ms | 2.07ms | **81.2%** â†‘ |
| Climate Change | 2.98ms | 1.97ms | **33.9%** â†‘ |
| Quantum Computing | 2.92ms | 2.06ms | **29.5%** â†‘ |
| Renewable Energy | 2.99ms | 2.15ms | **28.0%** â†‘ |
| Space Exploration | 2.06ms | 2.03ms | **1.5%** â†‘ |

**Average Improvement: 34.8%**  
**Best Performance: 81.2% faster (AI/ML query)**  
**Success Rate: 5/5 queries optimized (100%)**

---

## ğŸ“¸ Demo

![Benchmark Results](screenshots/benchmark_results.png)
*Agent achieved 81.2% optimization on first query through autonomous IVFFlat index selection*

![Agent Decision](screenshots/agent_decision.png)
*LLM-powered reasoning: Observe â†’ Reason â†’ Act â†’ Verify loop in action*

![Project Summary](screenshots/project_summary.png)
*Complete metrics: 995 documents, 28 total optimizations, 100% success rate*

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Query Request                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚  OBSERVE â”‚ â† PostgreSQL EXPLAIN ANALYZE
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   (Execution time, scan type, index usage)
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚  REASON  â”‚ â† Ollama (Phi-3 Mini LLM)
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   (HNSW vs IVFFlat decision)
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚   ACT    â”‚ â† CREATE INDEX (autonomous)
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   (IVFFlat/HNSW with params)
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚  VERIFY  â”‚ â† Re-measure & log metrics
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (Prometheus + Grafana)
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Database** | PostgreSQL 16 + pgvector | Vector storage & similarity search |
| **LLM** | Ollama (Phi-3 Mini) | Autonomous optimization decisions |
| **Embeddings** | sentence-transformers | Text-to-vector (384-dim) |
| **Monitoring** | Prometheus + Grafana | Real-time performance tracking |
| **Language** | Python 3.10+ | Agent orchestration |
| **Infrastructure** | Docker Compose | Multi-service deployment |
| **Connection Pool** | PgBouncer | 1000+ concurrent connections |
| **Replication** | PostgreSQL Streaming | Master-slave failover ready |

---

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop
- Python 3.10+
- 8GB RAM minimum
- 10GB disk space

### Installation

```bash
# 1. Clone repository
git clone https://github.com/merenceleby/postgres-vector-agent
cd postgres-vector-agent

# 2. Run setup
setup-windows.bat  # Windows
# OR
./scripts/setup.sh  # Linux/Mac

# 3. Activate Python environment
venv\Scripts\activate  # Windows
# OR
source venv/bin/activate  # Linux/Mac

# 4. Load sample data
python scripts/load_data.py --num-docs 1000

# 5. Run benchmark
python scripts/benchmark.py
```

**Expected output:**
```
ğŸ¯ AUTO-TUNING POSTGRESQL VECTOR STORE AGENT - BENCHMARK

Query 1/5: 'artificial intelligence and machine learning'
ğŸ“Š Execution Time: 10.99 ms (Before)
ğŸ§  LLM Decision: create_ivfflat_index
âš¡ Creating IVFFlat index...
âœ… Index created successfully
ğŸ“ˆ IMPROVEMENT: 81.2%
   Before: 10.99 ms â†’ After: 2.07 ms

======================================================================
ğŸ“Š BENCHMARK SUMMARY
Average Improvement: 34.8%
```

---

## ğŸ“ Project Structure

```
postgres-vector-agent/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ database.py           # PostgreSQL operations & EXPLAIN parsing
â”‚   â”œâ”€â”€ embeddings.py         # sentence-transformers integration
â”‚   â”œâ”€â”€ agent_core.py         # Observe-Reason-Act-Verify loop
â”‚   â”œâ”€â”€ query_analyzer.py      # Query plan analysis
â”‚   â””â”€â”€ optimizer.py          # LLM-powered decision engine
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml     # Multi-service orchestration
â”‚   â”œâ”€â”€ init.sql               # Schema + partitioning + extensions
â”‚   â””â”€â”€ postgresql.conf        # Tuned for vector workloads
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml         # Metrics collection config
â”‚   â””â”€â”€ grafana-dashboard.json # Visual metrics tracking
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh               # Linux/Mac automated setup
â”‚   â”œâ”€â”€ load_data.py           # Wikipedia data loader
â”‚   â”œâ”€â”€ benchmark.py           # Performance testing
â”‚   â”œâ”€â”€ clean_indexes.py       # Reset for testing
â”‚   â””â”€â”€ summary.py             # Project metrics display
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup-windows.bat          # Automated Windows setup
â””â”€â”€ README.md                  # Project documentation

```

---

## ğŸ“ Key Features

### 1. Autonomous Query Optimization
- Parses PostgreSQL `EXPLAIN ANALYZE` JSON output
- Detects sequential scans, missing indexes, and bottlenecks
- No manual intervention required

### 2. LLM-Powered Decision Making
- Uses Phi-3 (3.8B parameters) running locally via Ollama
- Analyzes query patterns and dataset characteristics
- Chooses between HNSW (speed) vs IVFFlat (memory)
- Low temperature (0.3) for consistent technical decisions

### 3. Production-Grade Infrastructure
- Multi-tenant partitioning with row-level security
- PgBouncer connection pooling (1000+ concurrent)
- Master-slave replication for high availability
- Prometheus + Grafana for observability

### 4. Vector Search Optimization
- pgvector extension for cosine similarity
- HNSW indexes (m=16, ef_construction=64)
- IVFFlat indexes (lists=100)
- 384-dimensional embeddings

---

## ğŸ“Š How It Works

### Observation Phase
```python
# Execute EXPLAIN ANALYZE
EXPLAIN (ANALYZE, FORMAT JSON)
SELECT content FROM documents
ORDER BY embedding <-> '[...]'::vector
LIMIT 5;

# Extract metrics:
# - Execution Time: 10.99 ms
# - Scan Type: Sequential Scan
# - Index Used: False
```

### Reasoning Phase
```python
# LLM receives prompt:
"""
PERFORMANCE METRICS:
- Execution Time: 10.99 ms
- Scan Type: Seq Scan
- Index Used: False

QUESTION: HNSW or IVFFlat?
"""

# LLM Response:
# ACTION: create_ivfflat_index
# REASONING: Memory efficiency for large dataset
# EXPECTED: 20-40x faster
```

### Action Phase
```sql
-- Agent executes:
CREATE INDEX idx_embedding_ivfflat_wikipedia
ON rag_system.documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### Verification Phase
```python
# Re-measure:
# Before: 10.99 ms
# After:  2.07 ms
# Improvement: 81.2%

# Log to database
INSERT INTO rag_system.agent_actions...
```

---

## ğŸ“Š Monitoring

### Grafana Dashboard
Access: `http://localhost:3000` (admin/admin)

**Metrics tracked:**
- Query execution time trends
- Index hit/miss ratio
- Agent optimization frequency
- Database connection pool utilization

### Database Stats
```sql
-- View query performance
SELECT * FROM rag_system.query_metrics
ORDER BY timestamp DESC LIMIT 10;

-- See agent decisions
SELECT action_type, reasoning, success
FROM rag_system.agent_actions
ORDER BY timestamp DESC;

-- Check indexes
SELECT * FROM rag_system.index_registry;
```

### Project Summary
```bash
python scripts/summary.py
```

---

## ğŸ§ª Testing

### Run Benchmark
```bash
python scripts/benchmark.py
```

### Clean State
```bash
python scripts/clean_indexes.py
```

### Load Custom Data
```python
from agent.database import DatabaseManager
from agent.embeddings import EmbeddingGenerator

db = DatabaseManager()
embedder = EmbeddingGenerator()

documents = [{
    'tenant_id': 'my_app',
    'content': 'Your text',
    'embedding': embedder.encode_query('Your text'),
    'metadata': {}
}]

db.insert_documents(documents)
```

---

## ğŸ¯ Use Cases

1. **RAG Pipeline Optimization** - Auto-tune vector search for LLM apps
2. **Multi-Tenant SaaS** - Per-tenant database optimization
3. **Production Monitoring** - Detect/fix slow queries autonomously
4. **Index Strategy Testing** - Compare HNSW vs IVFFlat
5. **Database Education** - Learn PostgreSQL optimization

---


## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file

---


## ğŸ‘¨â€ğŸ’» Author

**[Muhammed Eren Ã‡elebi]**  
Building autonomous database optimization for AI workloads

ğŸ“§ [E-mail](mailto:muhammederencelebii@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/merencelebi/)  
ğŸ™ [GitHub](https://github.com/merenceleby)

---
